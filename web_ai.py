import streamlit as st
from openai import OpenAI
from PyPDF2 import PdfReader

# 1. ç½‘é¡µé…ç½®
st.set_page_config(page_title="Astra", page_icon="ğŸ’«", layout="wide")
st.title("ğŸ’« Astra å°æ˜ŸAI")

# --- æ ¸å¿ƒè®°å¿†ï¼šåˆå§‹åŒ–å¯¹è¯è®°å¿† ---
if "messages" not in st.session_state:
    st.session_state.messages = [] # è¿™ä¸ªç›’å­ç”¨æ¥è£…æ‰€æœ‰çš„èŠå¤©è®°å½•

# 2. åˆå§‹åŒ–å®¢æˆ·ç«¯
client = OpenAI(
    api_key="sk-0a477b0f3c874c8184f0a2ec168c3f2d", 
    base_url="https://api.deepseek.com"
)

# 3. ä¾§è¾¹æ ï¼šæ–‡ä»¶å¤„ç†å’ŒåŠŸèƒ½åŒº
with st.sidebar:
    st.header("ğŸ“‚ æ–‡ä»¶ä¸Šä¼ ")
    uploaded_file = st.file_uploader("ä¸Šä¼  PDF æ–‡æ¡£", type="pdf")
    
    file_content = ""
    if uploaded_file:
        reader = PdfReader(uploaded_file)
        # æå–æ–‡å­—å¹¶é˜²æ­¢ç²˜è¿
        file_content = "\n".join([page.extract_text() for page in reader.pages if page.extract_text()])
        st.success("âœ… ä½ çš„æ–‡æ¡£å·²è£…è½½å®Œæ¯•ï¼")
    
    st.divider() # ç”»æ¡çº¿
    if st.button("ğŸ—‘ï¸ æ¸…ç©ºå¯¹è¯è®°å¿†"):
        st.session_state.messages = []
        st.rerun()

# 4. ä¸»ç•Œé¢ï¼šå±•ç¤ºå¯¹è¯å†å²
# ç”¨æ°”æ³¡çš„æ–¹å¼å±•ç¤ºä¹‹å‰èŠè¿‡çš„å†…å®¹
for message in st.session_state.messages:
    with st.chat_message(message["role"]):
        st.markdown(message["content"])

# 5. ä¸»ç•Œé¢ï¼šè¾“å…¥åŒº
# ä½¿ç”¨ st.chat_inputï¼Œå®ƒä¼šè‡ªåŠ¨å›ºå®šåœ¨é¡µé¢åº•éƒ¨ï¼Œä½“éªŒæå¥½
if user_question := st.chat_input("è·Ÿå°æ˜ŸèŠèŠä½ çš„è§„åˆ’ï¼Œæˆ–è€…é’ˆå¯¹æ–‡æ¡£æé—®..."):
    
    # A. å…ˆæŠŠä½ çš„é—®é¢˜å­˜è¿›è®°å¿†ï¼Œå¹¶æ˜¾ç¤ºåœ¨ç½‘é¡µä¸Š
    st.session_state.messages.append({"role": "user", "content": user_question})
    with st.chat_message("user"):
        st.markdown(user_question)

    # B. è°ƒç”¨ AI è¿›è¡Œå›ç­”
    with st.chat_message("assistant"):
        with st.spinner('Astra æ­£åœ¨æ€è€ƒä¸­...'):
            try:
                # è®¾å®š AI çš„äººè®¾ï¼ˆä½ å¯ä»¥æ ¹æ®éœ€è¦ä¿®æ”¹ï¼‰
                system_instruction = """ä½ æ˜¯ä¸€ä¸ªä¸–ç•Œé¡¶çº§çš„èŒä¸šç”Ÿæ¶¯è§„åˆ’ä¸“å®¶ï¼Œæ‹¥æœ‰å¿ƒç†å­¦å’ŒäººåŠ›èµ„æºç®¡ç†çš„åŒé‡èƒŒæ™¯ã€‚
                ä½ ä¼šé˜…è¯»ç”¨æˆ·ä¸Šä¼ çš„å†…å®¹ï¼Œå¹¶ç»“åˆä¸Šä¸‹æ–‡æä¾›æœ‰æ´å¯ŸåŠ›çš„åˆ†æã€‚
                å›ç­”è¦æ±‚ï¼šé€»è¾‘æ¸…æ™°ã€è¯­æ°”ä¸“ä¸šä¸”å¯Œæœ‰å¯å‘æ€§ï¼Œå¤šä½¿ç”¨ Markdown æ ¼å¼ï¼ˆæ ‡é¢˜ã€åŠ ç²—ã€åˆ—è¡¨ï¼‰ã€‚"""
                
                # å¦‚æœæœ‰ä¸Šä¼ æ–‡ä»¶ï¼Œå°±æŠŠæ–‡ä»¶å†…å®¹å¡è¿›ç³»ç»Ÿæç¤ºè¯é‡Œ
                if file_content:
                    system_instruction += f"\n\nä»¥ä¸‹æ˜¯å‚è€ƒæ–‡æ¡£å†…å®¹ï¼š\n{file_content}"

                # æ„é€ å‘é€ç»™ DeepSeek çš„å®Œæ•´æ¶ˆæ¯åˆ—è¡¨ï¼ˆç³»ç»Ÿäººè®¾ + å†å²è®°å¿†ï¼‰
                messages_for_api = [{"role": "system", "content": system_instruction}] + st.session_state.messages
                
                response = client.chat.completions.create(
                    model="deepseek-chat",
                    messages=messages_for_api,
                    stream=False # å¦‚æœæƒ³è¦æ‰“å­—æœºæ•ˆæœå¯ä»¥è®¾ä¸º Trueï¼Œæ–°æ‰‹å»ºè®®å…ˆé€‰ False
                )
                
                answer = response.choices[0].message.content
                
                # C. æŠŠ AI çš„å›ç­”å­˜è¿›è®°å¿†ï¼Œå¹¶æ˜¾ç¤ºå‡ºæ¥
                st.markdown(answer)
                st.session_state.messages.append({"role": "assistant", "content": answer})
                
            except Exception as e:
                st.error(f"å‘ç”Ÿé”™è¯¯ï¼š{e}")
